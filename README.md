# Monte-Carlo-Simulations-Gibbs-sampling-on-Drunkard-s-walk
In this repository we discuss and implement Gibbs sampling algorithm, a variant of MCMC(Monte Carlo Markov chain) on a simple random walk-based problem. 
